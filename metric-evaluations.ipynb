{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotator Metrics Evaluation\n",
    "This notebook is intended to run metric evaluations to compare the ground truth annotations for annotators on the Janelia CellMap team. Specifically, annotators have labeled organelles in 3D EM datasets and we want to compare their evaluations to see if there are any outliers that may need further practice.\n",
    "\n",
    "Data is expected to be subdivided into `groups` based on which organelles are labelled within them. `groups` are further divided into `crops` which correspond to specific region in the datasets that were labeled. `crops` contain the individual annotation images for each annotator in the region of interest. Optionally, the `crops` may also contain machine learning network predictions, refined segmentations from the predictions, and/or segmentations from Ariadne.\n",
    "\n",
    "For a given `group` and `crop`, the code in this notebook can be used to perform an all-to-all comparison across all annotators and a variety of metrics. In particular, there are four main functions used to run the code:\n",
    "1. `copy_data`: This function takes all the data from a source directory where it is organized in a predefined way and copies over into a new directory organized in a way better suited for the remainder of the analysis code. This only needs to be run once per `group`.\n",
    "2. `calculate_all_to_all`: This function uses Dask to actually do the all-to-all comparison across the desired metrics, returns the results as well as plots the results. This is calculated for each `crop` within a `group`, or for specific crops if provided.\n",
    "3. `create_variance_images`: For a given `group` and `crop`, this converts each annotation image into an n5 and calculates the variance across all manual annotations on a per-voxel basis, which itself is stored as an n5. This is calculated for each `crop` within a `group`, or for specific crops if provided.\n",
    "4. `get_neuroglancer_view_of_crop`: Given a path to a `crop` n5, this will provide a neuroglancer link to actually view and compare the annotations, raw data and variance image to better enable annotation comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying group2:\n",
      "Calculating all-to-all for group2 and 02:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://10.150.100.248:8787/status\">Click here to montior all-to-all calculation progress.</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating variance image for group2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://10.150.100.248:8787/status\">Click here to montior variance image creation progress.</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating neuroglancer image for group2 and 02:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://neuroglancer-demo.appspot.com#!%7B%22layers%22:%5B%7B%22type%22:%22image%22,%22source%22:%5B%7B%22url%22:%22n5://http://10.150.100.248:8080/ackermand/annotation_and_analytics/results/n5s/group2/02.n5/raw%22%7D%5D,%22name%22:%22raw%22%7D,%7B%22type%22:%22segmentation%22,%22source%22:%5B%7B%22url%22:%22n5://http://10.150.100.248:8080/ackermand/annotation_and_analytics/results/n5s/group2/02.n5/gt%22%7D%5D,%22name%22:%22gt%22,%22visible%22:false%7D,%7B%22type%22:%22segmentation%22,%22source%22:%5B%7B%22url%22:%22n5://http://10.150.100.248:8080/ackermand/annotation_and_analytics/results/n5s/group2/02.n5/a1%22%7D%5D,%22name%22:%22a1%22,%22visible%22:false%7D,%7B%22type%22:%22segmentation%22,%22source%22:%5B%7B%22url%22:%22n5://http://10.150.100.248:8080/ackermand/annotation_and_analytics/results/n5s/group2/02.n5/b1%22%7D%5D,%22name%22:%22b1%22,%22visible%22:false%7D,%7B%22type%22:%22segmentation%22,%22source%22:%5B%7B%22url%22:%22n5://http://10.150.100.248:8080/ackermand/annotation_and_analytics/results/n5s/group2/02.n5/c1%22%7D%5D,%22name%22:%22c1%22,%22visible%22:false%7D,%7B%22type%22:%22segmentation%22,%22source%22:%5B%7B%22url%22:%22n5://http://10.150.100.248:8080/ackermand/annotation_and_analytics/results/n5s/group2/02.n5/f1%22%7D%5D,%22name%22:%22f1%22,%22visible%22:false%7D,%7B%22type%22:%22segmentation%22,%22source%22:%5B%7B%22url%22:%22n5://http://10.150.100.248:8080/ackermand/annotation_and_analytics/results/n5s/group2/02.n5/predictions%22%7D%5D,%22name%22:%22predictions%22,%22visible%22:false%7D,%7B%22type%22:%22segmentation%22,%22source%22:%5B%7B%22url%22:%22n5://http://10.150.100.248:8080/ackermand/annotation_and_analytics/results/n5s/group2/02.n5/refinements%22%7D%5D,%22name%22:%22refinements%22,%22visible%22:false%7D,%7B%22type%22:%22image%22,%22source%22:%5B%7B%22url%22:%22n5://http://10.150.100.248:8080/ackermand/annotation_and_analytics/results/n5s/group2/02.n5/er-lum_variance%22%7D%5D,%22name%22:%22er-lum_variance%22,%22visible%22:false%7D,%7B%22type%22:%22image%22,%22source%22:%5B%7B%22url%22:%22n5://http://10.150.100.248:8080/ackermand/annotation_and_analytics/results/n5s/group2/02.n5/er-mem_variance%22%7D%5D,%22name%22:%22er-mem_variance%22,%22visible%22:false%7D,%7B%22type%22:%22image%22,%22source%22:%5B%7B%22url%22:%22n5://http://10.150.100.248:8080/ackermand/annotation_and_analytics/results/n5s/group2/02.n5/er_variance%22%7D%5D,%22name%22:%22er_variance%22,%22visible%22:false%7D%5D%7D\">Click here to view data on neuroglancer.</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the desired functions\n",
    "from annotator_metrics.src.preprocessing import copy_data\n",
    "from annotator_metrics.src.metrics_evaluations import calculate_all_to_all\n",
    "from annotator_metrics.util.image_io import (\n",
    "    create_variance_images,\n",
    "    get_neuroglancer_view,\n",
    ")\n",
    "\n",
    "# Specify the group and crop of interest\n",
    "group = \"group2\"\n",
    "crop = \"02\"\n",
    "\n",
    "# Specify base output path for where the data will be saved\n",
    "output_base_path = \"/groups/cellmap/cellmap/ackermand/annotation_and_analytics/\"\n",
    "\n",
    "# Copy the data\n",
    "print(f\"Copying {group}.\")\n",
    "copy_data(group=group, output_path=f\"{output_base_path}/data/\")\n",
    "\n",
    "# Do the all-to-all calculations\n",
    "print(f\"Calculating all-to-all for {group} and crop {crop}:\")\n",
    "all_to_all_info, scores_info = calculate_all_to_all(\n",
    "    group=group,\n",
    "    input_path=f\"{output_base_path}/data/\",\n",
    "    crop=crop,\n",
    "    output_path=f\"{output_base_path}/results/\",\n",
    "    num_workers=10,\n",
    ")\n",
    "\n",
    "# Create the variance image\n",
    "print(f\"Creating variance image for {group} and crop {crop}:\")\n",
    "create_variance_images(\n",
    "    input_path=f\"{output_base_path}/data/\",\n",
    "    group=group,\n",
    "    output_path=f\"{output_base_path}/results/n5s\",\n",
    "    crop=crop,\n",
    ")\n",
    "\n",
    "# Get a neuroglancer view of the crop. The http-served directory is /groups/cellmap/cellmap\n",
    "print(f\"Generating neuroglancer image for {group} and crop {crop}:\")\n",
    "get_neuroglancer_view(\n",
    "    n5s_path=f\"{output_base_path}/results/n5s\",\n",
    "    group = group\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d8da5ca0273e8c682ea917531ceab93fb623480edb88ccc1994af136416dea6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('annotator-metrics')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
